{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importa librería encargada de cargar los procesos para imágenes\n",
    "import cv2\n",
    "# Se importa numpy para el manejo de array\n",
    "import numpy as np \n",
    "# Se importa os para la lectura de directorio de imágenes\n",
    "from os import listdir\n",
    "# Se importa pyplot para mostrar imágenes y gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "# Se importa pandas para trabajar con csv\n",
    "import pandas as pd\n",
    "# Se importa math para funciones\n",
    "import math as mt\n",
    "\n",
    "\n",
    "# Se importa skimage feature para la extración de características de GLCM\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "# Se importan medidas de desempeño y error\n",
    "from sklearn import metrics\n",
    "# Se importan Repeated K-Fold Cross Validator para generar los conjuntos de Entrenamiento y Test \n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "# Se importa la función para el calculo de la precisión\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Se importa la función para obtener la matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Se importa el modelo de clasificación correspondiente a una SVM en este caso SVC (C-support vector classification)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Se importa scale para poder estandarizar los valores de los features para tener la misma escala \n",
    "from sklearn.preprocessing import scale\n",
    "# Se importa ssim para poder calcular la diferencia entre imágenes\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "# Se importa para poder calcular medidas de tendencia centrales\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(100)\n",
    "\n",
    "class BatAlgorithm():\n",
    "    def __init__(self, D, NB, N_Gen, A0, r0, alpha, gamma, Fmin, Fmax, LowerB, UpperB, function, imgSamples, dataSamples):\n",
    "        \n",
    "        # Inicialización de Parámetros\n",
    "        self.D = D  #dimension\n",
    "        self.NB = NB  #number of bats \n",
    "        self.N_Gen = N_Gen  #generations\n",
    "        self.alpha = alpha  # loudness update\n",
    "        self.gamma = gamma  # pulse rate update\n",
    "        self.r0 = r0 # Pulse rate initial\n",
    "        self.A0 = A0 # Loudnes initial\n",
    "        self.Fmin = Fmin  #frequency min\n",
    "        self.Fmax = Fmax  #frequency max\n",
    "        self.LowerB = LowerB  #lower bound\n",
    "        self.UpperB = UpperB  #upper bound\n",
    "        self.Funct = function #function to optimize\n",
    "        \n",
    "        # Data Training\n",
    "        self.imgSamples = imgSamples\n",
    "        self.dataSamples = dataSamples\n",
    "        \n",
    "        # Inicializar Loudness (A) y Pulse rate (R)\n",
    "        self.A = [self.A0 for i in range(self.NB)]\n",
    "        self.r = [self.r0 for i in range(self.NB)]\n",
    "        \n",
    "        # Inicializar limite inferior y superior para cada bat\n",
    "        self.Lb = [[0.0 for i in range(self.D)] for j in range(self.NB)]  #lower bound\n",
    "        self.Ub = [[0.0 for i in range(self.D)] for j in range(self.NB)]  #upper bound\n",
    "        \n",
    "        # Inicializar frecuencia\n",
    "        self.F = [0.0] * self.NB  #frequency\n",
    "\n",
    "        # Inicializar velocidad de los bats\n",
    "        self.v = [[0.0 for i in range(self.D)] for j in range(self.NB)]  #velocity\n",
    "        \n",
    "        # Inicilizar soluciones de los bats\n",
    "        self.Sol = [[0.0 for i in range(self.D)] for j in range(self.NB)]  #population of solutions\n",
    "        \n",
    "        # Inicilizar fitness de cada bat y el mejor fitness\n",
    "        self.Fitness = [0.0] * self.NB  #fitness\n",
    "        self.f_max = 0.0  #maximum fitness\n",
    "        \n",
    "        # Se agregan las variables de matriz de confusión\n",
    "        self.confM = [0.0] * self.NB #matriz de confusión\n",
    "        self.maxconfM = 0 #máxima matriz de confusión\n",
    "        \n",
    "        # Inicilizar la mejor solución encontrada\n",
    "        self.best = [0.0] * self.D  #best solution\n",
    "        \n",
    "        \n",
    "    def best_bat(self):\n",
    "        i = 0\n",
    "        j = 0\n",
    "        # Se obtiene el mejor bat de toda la 1ra generación\n",
    "        for i in range(self.NB):\n",
    "            if self.Fitness[i] > self.Fitness[j]: # Cambiar para max o min\n",
    "                j = i\n",
    "        # Se actualiza el fitness mejor y la sol para la 1ra vez\n",
    "        for i in range(self.D):\n",
    "            self.best[i] = self.Sol[j][i]\n",
    "        self.f_max = self.Fitness[j]\n",
    "        self.maxconfM = self.confM[j]\n",
    "\n",
    "    def init_bat(self):\n",
    "        # Iniciliza los limites para cada bat y variables\n",
    "        for i in range(self.NB):\n",
    "            for j in range(self.D):\n",
    "                self.Lb[i][j] = self.LowerB[j]\n",
    "                self.Ub[i][j] = self.UpperB[j]\n",
    "                \n",
    "        # Se inicializan las soluciones para cada bat\n",
    "        for i in range(self.NB):\n",
    "            self.F[i] = 0\n",
    "            for j in range(self.D):\n",
    "                rnd = np.random.uniform(0, 1)\n",
    "                self.v[i][j] = 0.0\n",
    "                self.Sol[i][j] = self.Lb[i][j] + (self.Ub[i][j] - self.Lb[i][j]) * rnd\n",
    "            self.Fitness[i], self.confM[i] = self.Funct(self.D, self.Sol[i], self.imgSamples, self.dataSamples)\n",
    "        \n",
    "        # Se selecciona el mejor bat de la generacion?\n",
    "        self.best_bat()\n",
    "\n",
    "    def simplebounds(self, val,index):\n",
    "        # Función encargada de normalizar las soluciones en los limites\n",
    "        if(index == 0):\n",
    "            if val > self.UpperB[index]:\n",
    "                val = self.UpperB[index]\n",
    "            if val < self.LowerB[index]:\n",
    "                val = self.LowerB[index]\n",
    "        if(index == 1):\n",
    "            if val > self.UpperB[index]:\n",
    "                val = self.UpperB[index]\n",
    "            if val < self.LowerB[index]:\n",
    "                val = self.LowerB[index]\n",
    "    \n",
    "        return val\n",
    "\n",
    "    def move_bat(self):\n",
    "        # Se inicializa matriz de soluciones \n",
    "        S = [[0.0 for i in range(self.D)] for j in range(self.NB)]\n",
    "\n",
    "        self.init_bat()\n",
    "\n",
    "        for t in range(self.N_Gen):\n",
    "            factor = np.mean(self.A)\n",
    "            for i in range(self.NB):\n",
    "                rnd = np.random.uniform(0, 1)\n",
    "                self.F[i] = self.Fmin + (self.Fmax - self.Fmin) * rnd\n",
    "                \n",
    "                for j in range(self.D):\n",
    "                    self.v[i][j] = self.v[i][j] + (self.best[j] - self.Sol[i][j]) * self.F[i]\n",
    "                    S[i][j] = self.Sol[i][j] + self.v[i][j]\n",
    "\n",
    "                    S[i][j] = self.simplebounds(S[i][j],j)\n",
    "\n",
    "                rnd = np.random.uniform(0,1)\n",
    "\n",
    "                if rnd > self.r[i]:\n",
    "                    for j in range(self.D):\n",
    "                        rnd = np.random.uniform(-1.0,1.0)\n",
    "                        S[i][j] = self.best[j] + rnd*factor\n",
    "                        S[i][j] = self.simplebounds(S[i][j],j)\n",
    "                        \n",
    "                Fnew, Mconf = self.Funct(self.D, S[i], self.imgSamples, self.dataSamples)\n",
    "\n",
    "                rnd = np.random.uniform(0,1)\n",
    "\n",
    "                if (Fnew > self.Fitness[i]) and (rnd < self.A[i]): # Cambiar para max o min\n",
    "                    for j in range(self.D):\n",
    "                        self.Sol[i][j] = S[i][j]\n",
    "                    self.Fitness[i] = Fnew\n",
    "                    self.confM[i] = Mconf\n",
    "\n",
    "                if Fnew > self.f_max: # Cambiar para max o min\n",
    "                    for j in range(self.D):\n",
    "                        self.best[j] = self.Sol[i][j]\n",
    "                    self.f_max = Fnew\n",
    "                    self.maxconfM = Mconf\n",
    "                    \n",
    "                    self.A[i] = self.A[i]*self.alpha\n",
    "                    self.r[i] = self.r0*(1 - mt.exp(-1*self.gamma*i))\n",
    "            print(\"\\nFitness de generación:\",self.Fitness)\n",
    "            print(\"Fitness mejor encontrado:\",self.f_max)\n",
    "            #print(\"Matriz de Confusión:\\n\",self.confM)\n",
    "            print(\"Solucion:\",self.best)\n",
    "                    \n",
    "        print (\"\\nFitness máximo: \",self.f_max)\n",
    "        print (\"Solución para máximo: \",self.best)\n",
    "        print (\"Matriz de Confusión: \",self.maxconfM)\n",
    "        return self.best, self.maxconfM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función encargada de cargar las imágenes y obtener sus features\n",
    "def cargarFotosYFeatures(path):\n",
    "    casos = listdir(path)\n",
    "    featureList = []\n",
    "    contadorCaso = 0\n",
    "    \n",
    "    #------------- SECCIÓN ENCARGADA DE CREAR LAS IMÁGENES A COMPARAR EN LA SSIM -------------#\n",
    "    imgNueva = np.zeros((75,100))\n",
    "    imgNueva2 = np.zeros((75,100))\n",
    "    lineThickness = 1\n",
    "    cv2.line(imgNueva, (0, 75), (100, 0), (255,255,255), lineThickness)\n",
    "    cv2.line(imgNueva2, (0, 75), (100, 45), (255,255,255), lineThickness)\n",
    "    #------------- SECCIÓN ENCARGADA DE CREAR LAS IMÁGENES A COMPARAR EN LA SSIM -------------#\n",
    "    \n",
    "    # Se cargan las imágenes y se extraen sus features\n",
    "    contador = 0\n",
    "    for caso in casos:\n",
    "        nombreImgs = listdir(path+caso+\"/\")\n",
    "        featureCaso = []\n",
    "        for nombre in nombreImgs:\n",
    "            if(nombre != \"Thumbs.db\"):\n",
    "                img = cv2.imread(path+caso+\"/\"+nombre)\n",
    "                img = getROIyFeatures(img,imgNueva,imgNueva2)\n",
    "                featureCaso.append(img)\n",
    "                contador = contador + 1\n",
    "        featureList.append(featureCaso)\n",
    "        contadorCaso = contadorCaso +1\n",
    "        if(contadorCaso%50 == 0):\n",
    "            print(\"Cargadas fotografías hasta caso: \"+caso)\n",
    "    print(\"Fotografías cargadas: \"+str(contador))\n",
    "    return featureList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función encargada de obtener ROI y features de estos\n",
    "def getROIyFeatures(img,imgNueva,imgNueva2):\n",
    "    # Se obtiene las 3 ROI a analizar\n",
    "    imgROI1 = img[0:36,50:100] \n",
    "    imgROI2 = img[36:75,0:50] \n",
    "    imgROI3 = img[36:75,50:100] \n",
    "    \n",
    "    # Se obtienen las features de cada ROI\n",
    "    features1 = np.array(getFeatures(imgROI1))\n",
    "    features2 = np.array(getFeatures(imgROI2))\n",
    "    features3 = np.array(getFeatures(imgROI3))\n",
    "    \n",
    "    # Se obtienen las features de la imagen para SSIM y MSE\n",
    "    features4 = np.array(getSSIMyMSE(img,imgNueva,imgNueva2))\n",
    "\n",
    "    # Se concatenan todas en un arreglo de 32 features\n",
    "    features = np.concatenate((features1,features2,features3,features4),axis= None)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función encargada de obtener los features por imagen\n",
    "def getFeatures(img):\n",
    "    features = []\n",
    "    \n",
    "    #------------------ HISTOGRAM ----------------------#\n",
    "    # Features de histograma\n",
    "    hist = histogram(img)\n",
    "    \n",
    "    mean = np.mean(hist)\n",
    "    std = np.std(hist) \n",
    "    \n",
    "    features.append(mean)\n",
    "    features.append(std)\n",
    "    \n",
    "    #------------------ HISTOGRAM ----------------------#\n",
    "    \n",
    "    img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    #------------------ GLCM ---------------------------#\n",
    "    \n",
    "    # Features de GLCM\n",
    "    glcm = greycomatrix(img, [1], [0], 256, symmetric=True, normed=True)\n",
    "    dissimilarity = greycoprops(glcm, 'dissimilarity')\n",
    "    contrast = greycoprops(glcm, 'contrast')\n",
    "    homogeneity = greycoprops(glcm, 'homogeneity')\n",
    "    ASM = greycoprops(glcm, 'ASM')\n",
    "    energy = greycoprops(glcm, 'energy')\n",
    "    correlation = greycoprops(glcm, 'correlation')\n",
    "    \n",
    "    # Características en 0 grados\n",
    "    features.append(float(dissimilarity))\n",
    "    features.append(float(contrast))\n",
    "    features.append(float(homogeneity))\n",
    "    features.append(float(ASM))\n",
    "    features.append(float(energy))\n",
    "    features.append(float(correlation))\n",
    "    \n",
    "    #------------------ GLCM ---------------------------#\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función encargada de calcular el histograma de colores de una imagen\n",
    "def histogram(img):\n",
    "    color = ('b','g','r')\n",
    "    for i, c in enumerate(color):\n",
    "        hist = cv2.calcHist([img], [i], None, [256], [0, 256])\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función encargada de calcular el error cuadrático medio entre 2 imágenes\n",
    "def mse(imageA, imageB):\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función encargada de calcular el índice de similaridad estructural\n",
    "def getSSIMyMSE(img,imgNueva,imgNueva2):\n",
    "    img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(img,100,200,apertureSize = 5)\n",
    "    \n",
    "    # Se aplica una máscara para obtener la 1ra sección a comparar por SSIM y MSE\n",
    "    mask = np.zeros(edges.shape, dtype=np.uint8)\n",
    "    roi_corners = np.array([[(90,10),(0,75),(90,0)]], dtype=np.int32)\n",
    "    ignore_mask_color = (255,)\n",
    "    cv2.fillPoly(mask, roi_corners, ignore_mask_color)\n",
    "    masked_image = cv2.bitwise_and(edges, mask)\n",
    "    \n",
    "    # Se aplica una máscara para obtener la 2da sección a comparar por SSIM y MSE\n",
    "    mask2 = np.zeros(edges.shape, dtype=np.uint8)\n",
    "    roi_corners2 = np.array([[(90,60),(0,75),(90,40)]], dtype=np.int32)\n",
    "    ignore_mask_color2 = (255,)\n",
    "    cv2.fillPoly(mask2, roi_corners2, ignore_mask_color2)\n",
    "    masked_image2 = cv2.bitwise_and(edges, mask2)\n",
    "    \n",
    "    # Se compara cada sección con la correspondiente recta para obtener las features\n",
    "    ssim_const = ssim(masked_image,imgNueva,data_range=imgNueva.max() - imgNueva.min())\n",
    "    MSE = mse(masked_image,imgNueva)\n",
    "    \n",
    "    ssim_const2 = ssim(masked_image,imgNueva2,data_range=imgNueva.max() - imgNueva.min())\n",
    "    MSE2 = mse(masked_image,imgNueva2) \n",
    "    \n",
    "    ssim_const3 = ssim(masked_image2,imgNueva,data_range=imgNueva.max() - imgNueva.min())\n",
    "    MSE3 = mse(masked_image2,imgNueva)\n",
    "    \n",
    "    ssim_const4 = ssim(masked_image2,imgNueva2,data_range=imgNueva.max() - imgNueva.min())\n",
    "    MSE4 = mse(masked_image2,imgNueva2)\n",
    "    \n",
    "    # Se agrega cada feature a un arreglo a retornar\n",
    "    features = []\n",
    "    features.append(ssim_const)\n",
    "    features.append(ssim_const2) \n",
    "    features.append(ssim_const3) \n",
    "    features.append(ssim_const4)\n",
    "    features.append(MSE)\n",
    "    features.append(MSE2) \n",
    "    features.append(MSE3) \n",
    "    features.append(MSE4)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se la información de los labels de cada imagen\n",
    "dataY = pd.read_csv(\"images_for_SVM/GRIGRI_training.csv\",header=None)\n",
    "dataY = pd.Series.ravel(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargadas fotografías hasta caso: 051\n",
      "Cargadas fotografías hasta caso: 105\n",
      "Cargadas fotografías hasta caso: 155\n",
      "Cargadas fotografías hasta caso: 205\n",
      "Cargadas fotografías hasta caso: 256\n",
      "Fotografías cargadas: 5900\n"
     ]
    }
   ],
   "source": [
    "# Se cargan las fotografías y se obtienen sus features\n",
    "featuresImgs = cargarFotosYFeatures(\"images_for_SVM/dirTraining/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se preparan los datos y labels para utilizarlos en la SVM\n",
    "imgSamples = []\n",
    "dataSamples = []\n",
    "for featureArray,label in zip(featuresImgs,dataY):\n",
    "    for featuresImg in featureArray:\n",
    "        imgSamples.append(featuresImg)\n",
    "        dataSamples.append(label)\n",
    "imgSamples = np.array(imgSamples)\n",
    "dataSamples = np.array(dataSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.03125000e+00 9.94633026e+01 1.67517007e+01 3.03686508e+03\n",
      " 8.52264619e-01 7.19409447e-01 8.48180080e-01 5.96968212e-01\n",
      " 7.61718750e+00 1.00648178e+02 3.05306122e+01 5.48792360e+03\n",
      " 7.54851656e-01 5.61961362e-01 7.49640822e-01 4.69728669e-01\n",
      " 7.61718750e+00 9.75972748e+01 2.74296180e+01 4.85718786e+03\n",
      " 7.42062090e-01 5.35533354e-01 7.31801444e-01 5.98688534e-01\n",
      " 8.28640987e-01 7.33960115e-01 6.51166252e-01 7.94100696e-01\n",
      " 1.59528000e+03 1.89006000e+03 3.26859000e+03 2.78307000e+03]\n",
      "[7.03125000e+00 9.89210663e+01 1.71201814e+01 3.06013379e+03\n",
      " 8.46715673e-01 7.07898201e-01 8.41366865e-01 6.11341923e-01\n",
      " 7.61718750e+00 9.91457291e+01 3.04086866e+01 5.39600157e+03\n",
      " 7.45315325e-01 5.45604218e-01 7.38650267e-01 5.03240217e-01\n",
      " 7.61718750e+00 9.56370926e+01 2.96336996e+01 5.27799058e+03\n",
      " 7.20978612e-01 5.03858654e-01 7.09830018e-01 5.94449402e-01\n",
      " 8.26631051e-01 7.25291968e-01 6.67342443e-01 8.10882725e-01\n",
      " 1.63863000e+03 1.93341000e+03 3.10386000e+03 2.58366000e+03]\n"
     ]
    }
   ],
   "source": [
    "print(imgSamples[0])\n",
    "print(imgSamples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se escalan los datos para que sean utilizables de manera efectiva por la SVM\n",
    "imgSamples = scale(imgSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.12420496  0.02930953  0.2319693   0.15126586  0.15668321\n",
      "  0.18202144 -0.0666501   0.         -0.01590059  1.1977845   1.58297467\n",
      " -0.3680254  -0.32268065 -0.30531525 -1.10232899  0.         -0.73672078\n",
      "  0.10888879 -0.10555908 -0.61779167 -0.6620214  -0.63960343  1.00106702\n",
      " -0.96162895 -0.25097419 -1.18567828 -1.12869364  0.45434818 -0.13648007\n",
      "  0.95361471  1.03634778]\n",
      "[ 0.         -0.01736246  0.14400655  0.27317081  0.01066442 -0.00706425\n",
      "  0.01748921  0.0915384   0.         -0.53421995  1.15987685  1.4244692\n",
      " -0.6752718  -0.65608973 -0.64748907 -0.49175616  0.         -1.10398265\n",
      "  0.50852279  0.32757502 -0.9906143  -1.01152485 -1.01279796  0.94542679\n",
      " -1.12747018 -0.64447646 -0.32164901 -0.12914905  0.65092031  0.04139323\n",
      "  0.47956034  0.43183608]\n"
     ]
    }
   ],
   "source": [
    "print(imgSamples[0])\n",
    "print(imgSamples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 32)\n",
      "(5900,)\n"
     ]
    }
   ],
   "source": [
    "# Se revisa la estructura de los datos previo al entrenamiento\n",
    "print(imgSamples.shape)\n",
    "print(dataSamples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función encargada de entrenar un modelo de SVM (esta función es utilizada por el algoritmo de optimización en un Bat)\n",
    "def optimizeModel(D,sol,imgSamples,dataSamples):\n",
    "    # Se generan arreglos para guardar las métricas para el modelo a entrenar\n",
    "    accuracyClasificacion = []\n",
    "    confusionM = 0\n",
    "    # Se generan los conjuntos para 5 Folds con 10 iteraciones del proceso y random_state fijado para obtener los mismos resultados\n",
    "    RepKFoldVal = RepeatedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "\n",
    "    # Se realiza una iteración para generar los conjuntos de entrenamiento y test luego del Repeated K-Fold Cross Validation\n",
    "    for indice_train, indice_test in RepKFoldVal.split(imgSamples,dataSamples):\n",
    "        # Se obtiene los arreglos con los conjuntos de entrenamiento y test\n",
    "        X_train, X_test = imgSamples[indice_train], imgSamples[indice_test]\n",
    "        Y_train, Y_test = dataSamples[indice_train], dataSamples[indice_test]\n",
    "\n",
    "        # Se instancia un clasificador de tipo SVM\n",
    "        svmClass = SVC(gamma=sol[0],kernel='rbf',C=sol[1])\n",
    "        svmClass.fit(X_train,Y_train)\n",
    "\n",
    "        # Se obtienen las predicciones del modelo SVM\n",
    "        predictSVM = svmClass.predict(X_test)\n",
    "        exactitud = accuracy_score(Y_test, predictSVM)\n",
    "        \n",
    "        # Se obtiene la matriz de confusión del modelo\n",
    "        confusionM = confusionM + confusion_matrix(Y_test, predictSVM)\n",
    "        \n",
    "        # Se obtiene la precisión del modelo SVM para esta iteración\n",
    "        accuracyClasificacion.append(exactitud)\n",
    "        \n",
    "    return np.mean(accuracyClasificacion), confusionM/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.8692372881355931, 0.9078813559322032, 0.9080508474576272, 0.9014406779661016, 0.9069491525423731, 0.9077966101694915, 0.9069491525423728, 0.892542372881356, 0.8939830508474575]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.8692372881355931, 0.9078813559322032, 0.9080508474576272, 0.9047457627118645, 0.9069491525423731, 0.9077966101694915, 0.9072881355932205, 0.9021186440677967, 0.8957627118644067]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.8692372881355931, 0.9078813559322032, 0.9080508474576272, 0.9047457627118645, 0.9069491525423731, 0.9077966101694915, 0.9072881355932205, 0.9021186440677967, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.8692372881355931, 0.9078813559322032, 0.9080508474576272, 0.9063559322033898, 0.9069491525423731, 0.9077966101694915, 0.9072881355932205, 0.9021186440677967, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.9000847457627119, 0.9078813559322032, 0.9080508474576272, 0.9063559322033898, 0.9069491525423731, 0.9077966101694915, 0.9072881355932205, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.9000847457627119, 0.9078813559322032, 0.9080508474576272, 0.9063559322033898, 0.9069491525423731, 0.9077966101694915, 0.9072881355932205, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.9000847457627119, 0.9078813559322032, 0.9080508474576272, 0.9072881355932203, 0.9072033898305085, 0.9077966101694915, 0.9072881355932205, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.9000847457627119, 0.9078813559322032, 0.9080508474576272, 0.9072881355932203, 0.9072033898305085, 0.9077966101694915, 0.9072881355932205, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.9000847457627119, 0.9078813559322032, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.9072881355932205, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.9000847457627119, 0.9078813559322032, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.9072881355932205, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.9000847457627119, 0.9078813559322032, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.9072881355932205, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9069491525423728, 0.9047457627118642, 0.9078813559322032, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9079661016949153, 0.9047457627118642, 0.9078813559322032, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9079661016949153, 0.9047457627118642, 0.9079661016949153, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9079661016949153, 0.9047457627118642, 0.9079661016949153, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9079661016949153, 0.9047457627118642, 0.9079661016949153, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9079661016949153, 0.9047457627118642, 0.9079661016949153, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9079661016949153, 0.9047457627118642, 0.9079661016949153, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9079661016949153, 0.9047457627118642, 0.9079661016949153, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness de generación: [0.9079661016949153, 0.9047457627118642, 0.9079661016949153, 0.9080508474576272, 0.9072881355932203, 0.9074576271186441, 0.9077966101694915, 0.908050847457627, 0.9071186440677966, 0.9049999999999999]\n",
      "Fitness mejor encontrado: 0.9080508474576272\n",
      "Solucion: [0.31920470153156716, 7.001560568663524]\n",
      "\n",
      "Fitness máximo:  0.9080508474576272\n",
      "Solución para máximo:  [0.31920470153156716, 7.001560568663524]\n",
      "Matriz de Confusión:  [[596.1  43.9]\n",
      " [ 64.6 475.4]]\n"
     ]
    }
   ],
   "source": [
    "# Se instancian los parámetros del Bat y se realiza el proceso de optimización\n",
    "ba = BatAlgorithm(2,10,20,0.95,0.1,0.95,0.95,0,1,[1/32, 4],[1, 8],optimizeModel,imgSamples,dataSamples)\n",
    "parametros, matriz = ba.move_bat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31920470153156716, 7.001560568663524]\n",
      "[[596.1  43.9]\n",
      " [ 64.6 475.4]]\n"
     ]
    }
   ],
   "source": [
    "# Se revisa el resultado de los parámetros obtenidos\n",
    "print(parametros)\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de iteración: 0.9059322033898305\n",
      "Matriz de confusión: \n",
      " [[620  43]\n",
      " [ 68 449]]\n",
      "Accuracy de iteración: 0.9042372881355932\n",
      "Matriz de confusión: \n",
      " [[1227   83]\n",
      " [ 141  909]]\n",
      "Accuracy de iteración: 0.9135593220338983\n",
      "Matriz de confusión: \n",
      " [[1807  129]\n",
      " [ 197 1407]]\n",
      "Accuracy de iteración: 0.9042372881355932\n",
      "Matriz de confusión: \n",
      " [[2391  169]\n",
      " [ 270 1890]]\n",
      "Accuracy de iteración: 0.9144067796610169\n",
      "Matriz de confusión: \n",
      " [[2987  213]\n",
      " [ 327 2373]]\n",
      "Accuracy de iteración: 0.911864406779661\n",
      "Matriz de confusión: \n",
      " [[3572  250]\n",
      " [ 394 2864]]\n",
      "Accuracy de iteración: 0.911864406779661\n",
      "Matriz de confusión: \n",
      " [[4173  303]\n",
      " [ 445 3339]]\n",
      "Accuracy de iteración: 0.8983050847457628\n",
      "Matriz de confusión: \n",
      " [[4772  359]\n",
      " [ 509 3800]]\n",
      "Accuracy de iteración: 0.911864406779661\n",
      "Matriz de confusión: \n",
      " [[5392  395]\n",
      " [ 577 4256]]\n",
      "Accuracy de iteración: 0.9042372881355932\n",
      "Matriz de confusión: \n",
      " [[5961  439]\n",
      " [ 646 4754]]\n",
      "Medidas Métricas del modelo de Estado:\n",
      "\n",
      "Accuracy del Modelo promedio:  0.9080508474576272\n",
      "Matriz de confusión promedio: \n",
      " [[596.1  43.9]\n",
      " [ 64.6 475.4]]\n"
     ]
    }
   ],
   "source": [
    "# Se generan arreglos para guardar las métricas para el modelo a entrenar\n",
    "accuracyClasificacion = []\n",
    "# Se define una variable para la matriz de confusión\n",
    "confusionM = 0\n",
    "\n",
    "# Se generan los conjuntos para 5 Folds con 10 iteraciones del proceso y random_state fijado para obtener los mismos resultados\n",
    "RepKFoldVal = RepeatedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "\n",
    "# Se realiza una iteración para generar los conjuntos de entrenamiento y test luego del Repeated K-Fold Cross Validation\n",
    "for indice_train, indice_test in RepKFoldVal.split(imgSamples,dataSamples):\n",
    "    # Se obtiene los arreglos con los conjuntos de entrenamiento y test\n",
    "    X_train, X_test = imgSamples[indice_train], imgSamples[indice_test]\n",
    "    Y_train, Y_test = dataSamples[indice_train], dataSamples[indice_test]\n",
    "    \n",
    "    # Se instancia un clasificador de tipo SVM\n",
    "    svmClass = SVC(gamma=parametros[0],kernel='rbf',C=parametros[1])\n",
    "    svmClass.fit(X_train,Y_train)\n",
    "   \n",
    "    # Se obtienen las predicciones del modelo SVM\n",
    "    predictSVM = svmClass.predict(X_test)\n",
    "    exactitud = accuracy_score(Y_test, predictSVM)\n",
    "    \n",
    "    # Se obtiene la matriz de confusión \n",
    "    confusionM = confusionM + confusion_matrix(Y_test, predictSVM)\n",
    "    \n",
    "    # Se obtiene la precisión del modelo SVM para esta iteración\n",
    "    accuracyClasificacion.append(exactitud)\n",
    "    print(\"Accuracy de iteración: \"+str(exactitud))\n",
    "    print(\"Matriz de confusión: \\n\",confusionM)\n",
    "# Se imprime la media de cada medida métrica para el modelo   \n",
    "print(\"Medidas Métricas del modelo de Estado:\\n\")\n",
    "print(\"Accuracy del Modelo promedio: \", np.mean(accuracyClasificacion))\n",
    "print(\"Matriz de confusión promedio: \\n\", confusionM/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
